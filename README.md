# Threat-Driven Frameworks for Privacy-Preserving Machine Learning (2017â€“2025)

*Authors:*  
Syed Ahsan Ahmed, Mohammed Saad Shareef 

Lords Institute of Engineering and Technology, Hyderabad, India  

---

### ğŸ§  Overview
This repository accompanies the survey paper:

> *Threat-Driven Frameworks for Privacy-Preserving Machine Learning: A Practitionerâ€™s Guide (2017â€“2025)*  
> Focused on mapping privacy threats (membership inference, model inversion, data extraction, poisoning, gradient leakage) to practical mitigation frameworks and decision matrices.

The repository provides all supplementary materialsâ€”benchmark tables, figures, framework metrics, and extended notesâ€”to support reproducibility and practitioner reference.

---

### ğŸ“ Repository Contents

| Folder | Description |
|--------|--------------|
| /paper | Paper outline, figures (flowchart, decision tree), and draft PDF. |
| /data | Benchmark data: attack-defense mapping and framework decision matrices. |
| /case-studies | Short applied notes (Healthcare, Edge, Finance, Smart City). |
| /extended-bibliography | Scholarcy-based summaries of 6 canonical threat papers. |

---

### ğŸ“Š Key Files

| File | Description |
|------|--------------|
| data/attack_defense_mapping.csv | Core dataset mapping threats â†’ impacts â†’ mitigations. |
| data/decision_matrix.csv | Comparative matrix of framework maturity, usability, and adoption. |
| paper/tables/Table1_Attack_Defense.md | Table used in Section 3 of the paper. |
| paper/figures/figure1_flowchart.svg | Visual mapping of threats to defense techniques. |
| case-studies/healthcare_FED-EHR.md | Privacy-preserving FL deployment in EHR settings. |

---

### ğŸ§© Methodology Summary
- *Data collection:* Canonical threat papers (2015â€“2024) via Scholarcy summarization.  
- *Framework mapping:* Evaluated frameworks include Opacus, TensorFlow Privacy, Flower, FATE, CrypTen, TenSEAL, Microsoft SEAL, and NVIDIA FLARE.  
- *Synthesis:* Mapped each frameworkâ€™s defensive scope (DP, FL, SMPC, HE) to corresponding threat vectors.  
- *Decision matrix:* Built based on criteriaâ€”usability, scalability, and real-world adoption.

---

### ğŸ“ˆ How to Cite
If you use this repository, please cite:
@article{shareef2025threatdrivenppml,
title={Threat-Driven Frameworks for Privacy-Preserving Machine Learning: A Practitionerâ€™s Guide (2017â€“2025)},
author={ Ahmed, Syed Ahsan and Shareef, Mohammed Saad},
year={2025},
journal={Preprint / Workshop Submission}
}

---

### ğŸ§± Future Work
This repository will expand with the experimental follow-up paper:
> *Secure and Private Fine-Tuning of LLMs with Parameter-Efficient Methods (DP + LoRA)*

That companion repo (tentative name: Privtune-DP-LoRA-Benchmark) will benchmark Opacus + Flower for differential-privacy fine-tuning in non-IID settings.

---

### ğŸ“œ License
This project is licensed under the *MIT* license.  
You are free to reuse, modify, or distribute the material with appropriate credit.

---

### ğŸ¤ Contributing
Pull requests are welcome for:
- Adding new frameworks or metrics  
- Extending case studies  
- Correcting references or figures  

To contribute:
1. Fork this repository.  
2. Create a branch (add-framework-xyz).  
3. Submit a pull request with a short description

---

### ğŸ”— Contact
For correspondence or collaboration: 
ğŸŒ [LinkedIn: Syed Ahsan Ahmed](https://www.linkedin.com/in/syed-ahsan-ahmed-17475a290/)
ğŸŒ [LinkedIn: Mohammed Saad Shareef](https://linkedin.com/in/yourprofile)
